{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from urllib.parse import quote  # 이 부분 추가\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "import threading\n",
    "import re  # 코드 상단에 추가\n",
    "\n",
    "# PDF 저장 디렉토리와 로그 디렉토리 설정\n",
    "PDF_DIR = \"data/skhynix\"\n",
    "LOG_DIR = \"data/logs\"\n",
    "\n",
    "# 디렉토리 생성\n",
    "os.makedirs(PDF_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "# 로그 설정\n",
    "log_file = os.path.join(LOG_DIR, f\"news_download_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file, encoding='utf-8'),\n",
    "        # logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WebDriver 인스턴스를 관리하는 싱글톤 클래스\n",
    "class ChromeDriverWrapper:\n",
    "    \"\"\"Chrome WebDriver를 관리하는 싱글톤 클래스\"\"\"\n",
    "    _instance = None\n",
    "    _driver = None\n",
    "    _lock = threading.Lock()\n",
    "    \n",
    "    @classmethod\n",
    "    def get_instance(cls):\n",
    "        if cls._instance is None:\n",
    "            with cls._lock:\n",
    "                if cls._instance is None:\n",
    "                    cls._instance = cls()\n",
    "        return cls._instance\n",
    "    \n",
    "    def get_driver(self):\n",
    "        if self._driver is None:\n",
    "            chrome_options = Options()\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "            chrome_options.add_argument(\"--no-sandbox\")\n",
    "            chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "            \n",
    "            self._driver = webdriver.Chrome(\n",
    "                service=Service(ChromeDriverManager().install()),\n",
    "                options=chrome_options\n",
    "            )\n",
    "        return self._driver\n",
    "    \n",
    "    def quit_driver(self):\n",
    "        if self._driver:\n",
    "            try:\n",
    "                self._driver.quit()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"드라이버 종료 중 오류: {str(e)}\")\n",
    "            finally:\n",
    "                self._driver = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SKHynixNewsScraper:\n",
    "    def __init__(self):\n",
    "        logging.info(\"스크래퍼 초기화 시작\")\n",
    "        self.base_url = \"https://news.skhynix.co.kr\"\n",
    "        \n",
    "        chrome_options = Options()\n",
    "        # chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "        chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "        \n",
    "        self.driver = webdriver.Chrome(\n",
    "            service=Service(ChromeDriverManager().install()),\n",
    "            options=chrome_options\n",
    "        )\n",
    "        self.wait = WebDriverWait(self.driver, 20)\n",
    "        self.articles = []\n",
    "        logging.info(\"스크래퍼 초기화 완료\")\n",
    "\n",
    "    def get_article_content(self, url):\n",
    "        \"\"\"개별 기사의 내용을 가져오는 메서드\"\"\"\n",
    "        logging.info(f\"기사 내용 추출 시작: {url}\")\n",
    "        \n",
    "        try:\n",
    "            # 현재 창의 핸들 저장\n",
    "            main_window = self.driver.current_window_handle\n",
    "            \n",
    "            # 새 창에서 링크 열기\n",
    "            self.driver.execute_script(f\"window.open('{url}', '_blank');\")\n",
    "\n",
    "            # 새 창으로 전환 전 지연\n",
    "            time.sleep(3)            \n",
    "\n",
    "            # 새 창으로 전환\n",
    "            WebDriverWait(self.driver, 10).until(lambda driver: len(driver.window_handles) > 1)\n",
    "            new_window = [handle for handle in self.driver.window_handles if handle != main_window][0]\n",
    "            self.driver.switch_to.window(new_window)\n",
    "            logging.info(\"새 창으로 전환 완료\")\n",
    "\n",
    "            # 페이지 로딩 대기\n",
    "            time.sleep(5)            \n",
    "\n",
    "            try:\n",
    "                # 본문 컨테이너 대기 및 찾기\n",
    "                content_container = WebDriverWait(self.driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"div.post-contents\"))\n",
    "                )\n",
    "                \n",
    "                # 본문 내용 추출\n",
    "                paragraphs = content_container.find_elements(By.TAG_NAME, \"p\")\n",
    "                content_texts = []\n",
    "                \n",
    "                for p in paragraphs:\n",
    "                    text = p.text.strip()\n",
    "                    if text and not text.startswith('* '):  # 각주 제외\n",
    "                        content_texts.append(text)\n",
    "                \n",
    "                content = '\\n'.join(content_texts)\n",
    "                \n",
    "                if content:\n",
    "                    logging.info(f\"본문 내용 추출 성공 (길이: {len(content)} 자)\")\n",
    "                    return content\n",
    "                else:\n",
    "                    logging.error(\"본문 내용이 비어있습니다\")\n",
    "                    return \"내용 추출 실패\"\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.error(f\"본문 추출 중 오류: {str(e)}\")\n",
    "                # 디버깅을 위한 현재 페이지 HTML 로깅\n",
    "                logging.debug(f\"현재 페이지 HTML: {self.driver.page_source}\")\n",
    "                return \"내용 추출 실패\"\n",
    "                \n",
    "            finally:\n",
    "                # 새 창 닫기\n",
    "                self.driver.close()\n",
    "                # 원래 창으로 돌아가기\n",
    "                self.driver.switch_to.window(main_window)\n",
    "                logging.info(\"원래 창으로 복귀 완료\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"기사 내용 추출 중 오류: {str(e)}\")\n",
    "            try:\n",
    "                self.driver.switch_to.window(main_window)\n",
    "                logging.info(\"에러 후 원래 창으로 복귀\")\n",
    "            except:\n",
    "                logging.error(\"원래 창으로 복귀 실패\")\n",
    "            return \"내용 추출 실패\"\n",
    "\n",
    "    def clean_content(self, content):\n",
    "        \"\"\"본문 내용 정제\"\"\"\n",
    "        # 불필요한 공백 제거\n",
    "        content = ' '.join(content.split())\n",
    "        \n",
    "        # 각주 표시(*) 제거\n",
    "        content = re.sub(r'\\*\\s*[^*]+\\*', '', content)\n",
    "        \n",
    "        # 빈 줄 제거\n",
    "        content = re.sub(r'\\n\\s*\\n', '\\n', content)\n",
    "        \n",
    "        return content.strip()\n",
    "\n",
    "    def search_news(self, keyword, page_limit=5):\n",
    "        logging.info(f\"뉴스 검색 시작 - 키워드: {keyword}, 페이지 제한: {page_limit}\")\n",
    "        current_page = 1\n",
    "        encoded_keyword = quote(keyword)\n",
    "        \n",
    "        try:\n",
    "            while current_page <= page_limit:\n",
    "\n",
    "                # newsroom\n",
    "                # if current_page == 1:\n",
    "                #     url = f\"{self.base_url}/?s={encoded_keyword}&type=newsroom\"\n",
    "                # else:\n",
    "                #     url = f\"{self.base_url}/page/{current_page}/?s={encoded_keyword}&type=newsroom\"\n",
    "\n",
    "                # press\n",
    "                if current_page == 1:\n",
    "                    url = f\"{self.base_url}/?s={encoded_keyword}&type=press\"\n",
    "                else:\n",
    "                    url = f\"{self.base_url}/page/{current_page}/?s={encoded_keyword}&type=press\"\n",
    "                \n",
    "                logging.info(f\"페이지 접근: {url}\")\n",
    "                self.driver.get(url)\n",
    "\n",
    "                # 페이지 로딩 대기\n",
    "                time.sleep(7)\n",
    "                \n",
    "                try:\n",
    "                    articles = self.driver.find_elements(By.TAG_NAME, \"article\")\n",
    "                    logging.info(f\"현재 페이지에서 {len(articles)}개의 기사 발견\")\n",
    "                    \n",
    "                    if not articles:\n",
    "                        logging.info(\"더 이상 기사가 없습니다\")\n",
    "                        break\n",
    "                    \n",
    "                    for article in articles:\n",
    "                        try:\n",
    "                            # 기사 처리 전 지연\n",
    "                            time.sleep(2)\n",
    "\n",
    "                            # 제목과 URL 추출\n",
    "                            title_selectors = [\n",
    "                                (By.CSS_SELECTOR, \"h2.tit a\"),\n",
    "                                (By.CSS_SELECTOR, \"a.tit\"),\n",
    "                                (By.TAG_NAME, \"a\")\n",
    "                            ]\n",
    "                            \n",
    "                            title = None\n",
    "                            url = None\n",
    "                            \n",
    "                            for selector_type, selector in title_selectors:\n",
    "                                try:\n",
    "                                    link_element = article.find_element(selector_type, selector)\n",
    "                                    title = link_element.text.strip()\n",
    "                                    url = link_element.get_attribute(\"href\")\n",
    "                                    if title and url:\n",
    "                                        break\n",
    "                                except:\n",
    "                                    continue\n",
    "                            \n",
    "                            if not title or not url:\n",
    "                                continue\n",
    "                            \n",
    "                            # 날짜 추출\n",
    "                            try:\n",
    "                                date_element = article.find_element(By.CLASS_NAME, \"date\")\n",
    "                                date = date_element.text.strip()\n",
    "                            except:\n",
    "                                date = \"날짜 정보 없음\"\n",
    "                            \n",
    "                            # 카테고리 추출\n",
    "                            try:\n",
    "                                category_elements = article.find_elements(By.CSS_SELECTOR, \"div.category a\")\n",
    "                                categories = [cat.text.strip() for cat in category_elements]\n",
    "                                category = \" \".join(categories)\n",
    "                            except:\n",
    "                                category = \"카테고리 없음\"\n",
    "                            \n",
    "                            # 태그 추출\n",
    "                            try:\n",
    "                                tag_elements = article.find_elements(By.CSS_SELECTOR, \"ul.tags li a\")\n",
    "                                tags = [tag.text.strip() for tag in tag_elements]\n",
    "                                tags_text = \", \".join(tags)\n",
    "                            except:\n",
    "                                tags_text = \"태그 없음\"\n",
    "                            \n",
    "                            # 기사 내용 가져오기\n",
    "                            content = self.get_article_content(url)\n",
    "                            \n",
    "                            article_data = {\n",
    "                                \"title\": title,\n",
    "                                \"url\": url,\n",
    "                                \"date\": date,\n",
    "                                \"category\": category,\n",
    "                                \"tags\": tags_text,\n",
    "                                \"content\": content\n",
    "                            }\n",
    "                            \n",
    "                            self.articles.append(article_data)\n",
    "                            logging.info(f\"기사가 성공적으로 추가됨: {title}\")\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            logging.error(f\"기사 정보 추출 중 오류: {str(e)}\")\n",
    "                    \n",
    "                    # 다음 페이지 확인\n",
    "                    try:\n",
    "                        next_page = self.driver.find_element(\n",
    "                            By.CSS_SELECTOR,\n",
    "                            f\"div.list-pagination a.page[href*='/page/{current_page + 1}/']\"\n",
    "                        )\n",
    "                        current_page += 1\n",
    "                        logging.info(f\"다음 페이지로 이동: {current_page}\")\n",
    "                    except:\n",
    "                        logging.info(\"마지막 페이지에 도달했습니다\")\n",
    "                        break\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logging.error(f\"페이지 처리 중 오류: {str(e)}\")\n",
    "                    break\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"검색 중 오류 발생: {str(e)}\")\n",
    "        \n",
    "        finally:\n",
    "            logging.info(f\"검색 완료 - 총 {len(self.articles)}개의 기사 수집\")\n",
    "\n",
    "    def save_to_csv(self, filename):\n",
    "        logging.info(f\"CSV 파일 저장 시작: {filename}\")\n",
    "        try:\n",
    "            if not self.articles:\n",
    "                logging.warning(\"저장할 기사가 없습니다\")\n",
    "                return\n",
    "                \n",
    "            df = pd.DataFrame(self.articles)\n",
    "            df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "            logging.info(\"CSV 파일 저장 완료\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"CSV 파일 저장 중 오류: {str(e)}\")\n",
    "\n",
    "    def __del__(self):\n",
    "        try:\n",
    "            self.driver.quit()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    scraper = SKHynixNewsScraper()\n",
    "    scraper.search_news(\"리더십\", page_limit=10)\n",
    "    scraper.save_to_csv(\"data/skhynix/leadership_press.csv\")\n",
    "finally:\n",
    "    scraper.__del__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
